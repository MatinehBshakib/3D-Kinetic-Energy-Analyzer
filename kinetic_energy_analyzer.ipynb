{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a86d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.21.2 (from opencv-python)\n",
      "  Using cached numpy-2.2.5-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Downloading numpy-2.2.5-cp310-cp310-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-2.2.5 opencv-python-4.11.0.86\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp310-cp310-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.2 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.11.1 (from jax->mediapipe)\n",
      "  Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Using cached fonttools-4.57.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/matineh/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
      "  Using cached pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/matineh/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /Users/matineh/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached mediapipe-0.10.21-cp310-cp310-macosx_11_0_universal2.whl (49.2 MB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached jaxlib-0.6.0-cp310-cp310-macosx_11_0_arm64.whl (53.5 MB)\n",
      "Using cached matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl (8.0 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\n",
      "Using cached sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.57.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl (671 kB)\n",
      "Using cached pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sentencepiece, flatbuffers, pyparsing, pycparser, protobuf, pillow, opt_einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed CFFI-1.17.1 absl-py-2.2.2 attrs-25.3.0 contourpy-1.3.2 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.57.0 jax-0.6.0 jaxlib-0.6.0 kiwisolver-1.4.8 matplotlib-3.10.1 mediapipe-0.10.21 ml_dtypes-0.5.1 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 pillow-11.2.1 protobuf-4.25.7 pycparser-2.22 pyparsing-3.2.3 scipy-1.15.2 sentencepiece-0.2.0 sounddevice-0.5.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f563481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing knietic_energy_analyzer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile knietic_energy_analyzer.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time\n",
    "import platform\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Define landmark subsets from your original code\n",
    "LANDMARK_SUBSETS = {\n",
    "    \"whole_body\": list(range(33)),  # All landmarks\n",
    "    \"upper_body\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "    \"lower_body\": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n",
    "    \"right_arm\": [11, 13, 15, 17, 19, 21],  # Right shoulder to right wrist and hand\n",
    "    \"left_arm\": [12, 14, 16, 18, 20, 22],   # Left shoulder to left wrist and hand\n",
    "    \"right_leg\": [23, 25, 27, 29, 31],      # Right hip to right ankle and foot\n",
    "    \"left_leg\": [24, 26, 28, 30, 32],       # Left hip to left ankle and foot\n",
    "}\n",
    "\n",
    "# Your original KineticEnergyAnalyzer class\n",
    "class KineticEnergyAnalyzer:\n",
    "    def __init__(self, window_size=10):\n",
    "        self.window_size = window_size\n",
    "        self.landmark_positions = [deque(maxlen=window_size) for _ in range(33)]\n",
    "        self.velocities = [[] for _ in range(33)]\n",
    "        self.last_timestamps = [None for _ in range(33)]\n",
    "        self.kinetic_energies = {subset: 0.0 for subset in LANDMARK_SUBSETS.keys()}\n",
    "        self.gesture_energies = []\n",
    "        self.current_gesture_energies = {subset: 0.0 for subset in LANDMARK_SUBSETS.keys()}\n",
    "        self.gesture_active = False\n",
    "        # Assuming each landmark has equal mass (can be modified if needed)\n",
    "        self.mass = 1.0\n",
    "        \n",
    "    def update_positions(self, landmarks, timestamp):\n",
    "        \"\"\"Update position history for each landmark\"\"\"\n",
    "        for i, landmark in enumerate(landmarks.landmark[:33]):  # Using only the first 33 landmarks\n",
    "            position = np.array([landmark.x, landmark.y, landmark.z])\n",
    "            \n",
    "            # If this is a valid position (not NaN)\n",
    "            if not np.isnan(position).any():\n",
    "                # Add position to history\n",
    "                self.landmark_positions[i].append((position, timestamp))\n",
    "                \n",
    "                # Calculate velocity if we have previous position\n",
    "                if self.last_timestamps[i] is not None:\n",
    "                    time_delta = timestamp - self.last_timestamps[i]\n",
    "                    if time_delta > 0:\n",
    "                        prev_position = self.landmark_positions[i][-2][0]\n",
    "                        velocity = (position - prev_position) / time_delta\n",
    "                        self.velocities[i].append(velocity)\n",
    "                        \n",
    "                self.last_timestamps[i] = timestamp\n",
    "    \n",
    "    def compute_kinetic_energy(self):\n",
    "        \"\"\"Compute kinetic energy for all landmarks and subsets\"\"\"\n",
    "        # Reset kinetic energies\n",
    "        for subset in LANDMARK_SUBSETS.keys():\n",
    "            self.kinetic_energies[subset] = 0.0\n",
    "        \n",
    "        # Compute kinetic energy for each landmark\n",
    "        landmark_ke = [0.0] * 33\n",
    "        \n",
    "        for i in range(33):\n",
    "            if len(self.velocities[i]) > 0:\n",
    "                # Use the most recent velocity\n",
    "                v = self.velocities[i][-1]\n",
    "                # KE = 0.5 * m * |v|^2\n",
    "                ke = 0.5 * self.mass * np.sum(v**2)\n",
    "                landmark_ke[i] = ke\n",
    "        \n",
    "        # Accumulate kinetic energy for each subset\n",
    "        for subset_name, indices in LANDMARK_SUBSETS.items():\n",
    "            self.kinetic_energies[subset_name] = sum(landmark_ke[i] for i in indices if i < len(landmark_ke))\n",
    "        \n",
    "        return self.kinetic_energies\n",
    "    \n",
    "    def start_gesture(self):\n",
    "        \"\"\"Mark the beginning of a gesture\"\"\"\n",
    "        self.gesture_active = True\n",
    "        self.current_gesture_energies = {subset: 0.0 for subset in LANDMARK_SUBSETS.keys()}\n",
    "        \n",
    "    def update_gesture_energy(self):\n",
    "        \"\"\"Update the energy for the current gesture\"\"\"\n",
    "        if self.gesture_active:\n",
    "            for subset in LANDMARK_SUBSETS.keys():\n",
    "                self.current_gesture_energies[subset] += self.kinetic_energies[subset]\n",
    "    \n",
    "    def end_gesture(self):\n",
    "        \"\"\"Mark the end of a gesture and store its energies\"\"\"\n",
    "        if self.gesture_active:\n",
    "            # Average the energies over the gesture duration\n",
    "            num_frames = len(self.velocities[0]) if self.velocities[0] else 1\n",
    "            avg_energies = {subset: energy / num_frames \n",
    "                           for subset, energy in self.current_gesture_energies.items()}\n",
    "            \n",
    "            self.gesture_energies.append(avg_energies)\n",
    "            self.gesture_active = False\n",
    "    \n",
    "    def analyze_distribution(self, energies=None):\n",
    "        \"\"\"Analyze the distribution of kinetic energy among body parts\"\"\"\n",
    "        if energies is None:\n",
    "            energies = self.kinetic_energies\n",
    "        \n",
    "        # Skip whole_body as it's the sum of all others\n",
    "        subsets = [\"upper_body\", \"lower_body\", \"right_arm\", \"left_arm\", \"right_leg\", \"left_leg\"]\n",
    "        \n",
    "        # If whole_body energy is very small, return early\n",
    "        if energies[\"whole_body\"] < 1e-6:\n",
    "            return {subset: 0 for subset in subsets}, \"No significant movement detected\"\n",
    "        \n",
    "        # Calculate percentages\n",
    "        percentages = {subset: (energies[subset] / energies[\"whole_body\"]) * 100 \n",
    "                      for subset in subsets}\n",
    "        \n",
    "        # Determine if any part is moving significantly more\n",
    "        threshold = 40  # If a part has more than 40% of total energy\n",
    "        max_subset = max(percentages.items(), key=lambda x: x[1])\n",
    "        \n",
    "        if max_subset[1] > threshold:\n",
    "            message = f\"The {max_subset[0].replace('_', ' ')} is moving a lot\"\n",
    "        else:\n",
    "            message = \"All limbs are moving relatively uniformly\"\n",
    "            \n",
    "        return percentages, message\n",
    "    \n",
    "    def visualize_distribution(self, percentages):\n",
    "        \"\"\"Create a bar chart of energy distribution\"\"\"\n",
    "        subsets = list(percentages.keys())\n",
    "        values = list(percentages.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(subsets, values, color='skyblue')\n",
    "        \n",
    "        # Add percentage labels on top of each bar\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}%',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.xlabel('Body Part')\n",
    "        plt.ylabel('Percentage of Total Kinetic Energy')\n",
    "        plt.title('Distribution of Kinetic Energy Across Body Parts')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.gcf()\n",
    "\n",
    "# Modified analyze_webcam function for macOS compatibility\n",
    "def analyze_webcam(duration=30, show_video=True, detection_threshold=0.5, gesture_detection_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Analyze body movement from webcam using MediaPipe - fixed for macOS compatibility\n",
    "    \n",
    "    Parameters:\n",
    "    - duration: Duration to capture in seconds\n",
    "    - show_video: Whether to show the video feed with pose overlay\n",
    "    - detection_threshold: Confidence threshold for pose detection\n",
    "    - gesture_detection_threshold: Energy threshold for gesture detection\n",
    "    \n",
    "    Returns:\n",
    "    - analyzer: The KineticEnergyAnalyzer object with computed data\n",
    "    - percentages: Distribution of energy across body parts\n",
    "    - message: Analysis result message\n",
    "    \"\"\"\n",
    "    print(\"Starting camera initialization...\")\n",
    "    \n",
    "    # On macOS, we need to be extra careful with camera handling\n",
    "    is_macos = platform.system() == \"Darwin\"\n",
    "    if is_macos:\n",
    "        print(\"Running on macOS - using macOS-specific camera handling\")\n",
    "    \n",
    "    # Initialize camera - try a few times if needed\n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            print(f\"Camera initialization attempt {attempt+1}/{max_attempts}\")\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            \n",
    "            # Important: Give camera time to initialize on macOS\n",
    "            time.sleep(1)\n",
    "            \n",
    "            if not cap.isOpened():\n",
    "                print(\"Failed to open camera - retrying...\")\n",
    "                cap.release()\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "                \n",
    "            # Try reading a test frame to verify camera is working\n",
    "            ret, test_frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Camera opened but failed to read test frame - retrying...\")\n",
    "                cap.release()\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "                \n",
    "            print(f\"Camera initialized successfully! Resolution: {test_frame.shape[1]}x{test_frame.shape[0]}\")\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during camera initialization: {e}\")\n",
    "            if 'cap' in locals() and cap is not None:\n",
    "                cap.release()\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        # If we've exhausted all attempts\n",
    "        print(\"ERROR: Could not initialize camera after multiple attempts.\")\n",
    "        print(\"Please check your camera permissions:\")\n",
    "        print(\"1. System Settings > Privacy & Security > Camera\")\n",
    "        print(\"2. Make sure your terminal/Python application has permission\")\n",
    "        print(\"3. Try closing any other applications that might be using the camera\")\n",
    "        return None, {}, \"Camera initialization failed\"\n",
    "    \n",
    "    # Setup MediaPipe Pose\n",
    "    print(\"Initializing pose detection...\")\n",
    "    analyzer = KineticEnergyAnalyzer()\n",
    "    \n",
    "    with mp_pose.Pose(\n",
    "        min_detection_confidence=detection_threshold,\n",
    "        min_tracking_confidence=detection_threshold,\n",
    "        model_complexity=1) as pose:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        frame_count = 0\n",
    "        \n",
    "        # For gesture detection\n",
    "        current_gesture_energy = 0\n",
    "        in_gesture = False\n",
    "        \n",
    "        print(f\"Starting webcam analysis for {duration} seconds...\")\n",
    "        print(\"Press ESC to stop early\")\n",
    "        \n",
    "        # Start a gesture\n",
    "        analyzer.start_gesture()\n",
    "        \n",
    "        while True:\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - start_time\n",
    "            \n",
    "            # Check if we've reached the duration\n",
    "            if elapsed_time > duration:\n",
    "                break\n",
    "                \n",
    "            # Read frame\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Failed to read frame - skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Convert the BGR image to RGB and process it\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image)\n",
    "            \n",
    "            # If pose landmarks are detected\n",
    "            if results.pose_landmarks:\n",
    "                timestamp = current_time\n",
    "                analyzer.update_positions(results.pose_landmarks, timestamp)\n",
    "                energy = analyzer.compute_kinetic_energy()\n",
    "                analyzer.update_gesture_energy()\n",
    "                \n",
    "                # Gesture detection\n",
    "                whole_body_energy = energy[\"whole_body\"]\n",
    "                \n",
    "                # Start a new gesture if energy exceeds threshold and we're not in a gesture\n",
    "                if whole_body_energy > gesture_detection_threshold and not in_gesture:\n",
    "                    print(\"Gesture started\")\n",
    "                    in_gesture = True\n",
    "                \n",
    "                # End gesture if energy drops below threshold and we're in a gesture\n",
    "                if whole_body_energy < gesture_detection_threshold and in_gesture:\n",
    "                    print(\"Gesture ended\")\n",
    "                    in_gesture = False\n",
    "                \n",
    "                # Analyze every 10 frames for display\n",
    "                if frame_count % 10 == 0:\n",
    "                    percentages, message = analyzer.analyze_distribution()\n",
    "                    time_left = duration - elapsed_time\n",
    "                    print(f\"Time left: {time_left:.1f}s | {message}\")\n",
    "                    \n",
    "                    if show_video:\n",
    "                        # Draw the pose detection on the image\n",
    "                        image.flags.writeable = True\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image,\n",
    "                            results.pose_landmarks,\n",
    "                            mp_pose.POSE_CONNECTIONS,\n",
    "                            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                        \n",
    "                        # Show energy info on the image\n",
    "                        info_text = f\"Time: {elapsed_time:.1f}s/{duration}s\"\n",
    "                        cv2.putText(image, info_text, (10, 30), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                        cv2.putText(image, message, (10, 60), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Display the image\n",
    "                        cv2.imshow('Body Movement Analysis', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Process key presses - using waitKey(1) for better responsiveness\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == 27:  # ESC key\n",
    "                print(\"Analysis stopped early\")\n",
    "                break\n",
    "        \n",
    "        # End any active gesture\n",
    "        analyzer.end_gesture()\n",
    "    \n",
    "    # Properly release camera\n",
    "    print(\"Analysis complete - releasing camera...\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Final analysis\n",
    "    if analyzer.gesture_energies:\n",
    "        # Average the energies across all detected gestures\n",
    "        avg_energies = {subset: 0 for subset in LANDMARK_SUBSETS.keys()}\n",
    "        \n",
    "        for gesture_energy in analyzer.gesture_energies:\n",
    "            for subset, energy in gesture_energy.items():\n",
    "                avg_energies[subset] += energy\n",
    "        \n",
    "        # Divide by number of gestures\n",
    "        num_gestures = len(analyzer.gesture_energies)\n",
    "        if num_gestures > 0:\n",
    "            for subset in avg_energies:\n",
    "                avg_energies[subset] /= num_gestures\n",
    "        \n",
    "        percentages, message = analyzer.analyze_distribution(avg_energies)\n",
    "    else:\n",
    "        percentages, message = analyzer.analyze_distribution()\n",
    "    \n",
    "    print(\"\\nFinal Analysis:\")\n",
    "    print(message)\n",
    "    print(\"\\nEnergy Distribution (%):\")\n",
    "    for subset, percentage in percentages.items():\n",
    "        if subset != \"whole_body\":  # Skip whole_body as it's always 100%\n",
    "            print(f\"{subset}: {percentage:.2f}%\")\n",
    "    \n",
    "    # Visualize the distribution\n",
    "    fig = analyzer.visualize_distribution(percentages)\n",
    "    plt.show()\n",
    "    \n",
    "    return analyzer, percentages, message\n",
    "\n",
    "# Simple test function for camera\n",
    "def test_camera():\n",
    "    \"\"\"Simple test function to verify camera access\"\"\"\n",
    "    print(\"Testing camera access...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open camera\")\n",
    "        return False\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "    print(f\"Successfully read frame with shape {frame.shape}\")\n",
    "    cap.release()\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # First run a simple test\n",
    "    if test_camera():\n",
    "        print(\"\\nCamera test passed! Running main analysis...\")\n",
    "        # Run the analysis\n",
    "        analyzer, percentages, message = analyze_webcam(duration=30)\n",
    "    else:\n",
    "        print(\"\\nCamera test failed. Please check your camera permissions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
